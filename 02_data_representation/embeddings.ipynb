{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "An embedding is a low-dimensional, vector representation of a (typically) high-dimensional feature which maintains the semantic meaning of the feature in a such a way that similar features are close in the embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks, layers, models, utils\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow_hub import KerasLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer for categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_pounds,is_male,mother_age,plurality,gestation_weeks\n",
      "5.2690480617999995,false,15,Single(1),28\n",
      "6.37576861704,Unknown,15,Single(1),30\n",
      "7.7492485093,true,42,Single(1),31\n",
      "1.25002102554,true,14,Twins(2),25\n",
      "8.68841774542,true,15,Single(1),31\n",
      "1.25002102554,Unknown,42,Single(1),23\n",
      "7.50012615324,true,15,Single(1),45\n",
      "6.37576861704,true,15,Single(1),47\n",
      "4.7509617461,true,42,Single(1),25\n"
     ]
    }
   ],
   "source": [
    "!head ./data/babyweight_sample.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Single(1)\n",
       "1    Single(1)\n",
       "2    Single(1)\n",
       "3     Twins(2)\n",
       "4    Single(1)\n",
       "Name: plurality, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/babyweight_sample.csv\") \n",
    "df.plurality.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Single(1)', 'Twins(2)', 'Triplets(3)', 'Multiple(2+)',\n",
       "       'Quadruplets(4)'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.plurality.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = {\n",
    "    'Single(1)': 0,\n",
    "    'Multiple(2+)': 1,\n",
    "    'Twins(2)': 2,\n",
    "    'Triplets(3)': 3,\n",
    "    'Quadruplets(4)': 4,\n",
    "    'Quintuplets(5)': 5\n",
    "}\n",
    "N_CLASSES = len(CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the plurality to a numeric index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plurality_class = [CLASSES[plurality] for plurality in df.plurality]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Single(1)\n",
      "1    Single(1)\n",
      "2    Single(1)\n",
      "3     Twins(2)\n",
      "4    Single(1)\n",
      "Name: plurality, dtype: object\n",
      "[0, 0, 0, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "print(df.plurality[:5])\n",
    "print(plurality_class[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an embedding layer. Supply arguments `input_dim` and `output_dim`\n",
    " - `input_dim` indicates the size of the vocabulary. For `plurality` this is 6.\n",
    " - `ouptut_dim` indicates the dimension of the dense embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = 2\n",
    "\n",
    "embedding_layer = layers.Embedding(input_dim=N_CLASSES,\n",
    "                                   output_dim=EMBED_DIM)\n",
    "embeds = embedding_layer(tf.constant(plurality_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `embeds` contains the two-dimensional for each plurality class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([999, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       "array([[-0.03752286, -0.00373652],\n",
       "       [-0.03752286, -0.00373652],\n",
       "       [-0.03752286, -0.00373652],\n",
       "       [-0.04066921,  0.00713168],\n",
       "       [-0.03752286, -0.00373652]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Layers in a Keras model\n",
    "\n",
    "In this section, we will implement text models to recognize the probable source (Github, Tech-Crunch, or The New-York Times) of the titles we have in the title dataset we constructed in the previous lab.\n",
    "\n",
    "In a first step, we will load and pre-process the texts and labels so that they are suitable to be fed to a Keras model. For the texts of the titles we will learn how to split them into a list of tokens, and then how to map each token to an integer using the Keras Tokenizer class. What will be fed to our Keras models will be batches of padded list of integers representing the text. For the labels, we will learn how to one-hot-encode each of the 3 classes into a 3 dimensional basis vector.\n",
    "\n",
    "Then we will explore a few possible models to do the title classification. All models will be fed padded list of integers, and all models will start with a Keras Embedding layer that transforms the integer representing the words into dense vectors.\n",
    "\n",
    "Our model will be a simple bag-of-words DNN model that averages up the word vectors and feeds the tensor that results to further dense layers. Doing so means that we forget the word order (and hence that we consider sentences as a “bag-of-words”). Using an RNN or a 1-dimensional CNN would allow us to maintain the order of word embeddings in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by specifying where the information about the trained models will be saved as well as where our dataset is located:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = \"./text_models\"\n",
    "DATA_DIR = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset consists of titles of articles along with the label indicating from which source these articles have been taken from (GitHub, Tech-Crunch, or the New-York Times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>holy cash cow  batman - content is back</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>show hn  a simple and configurable deployment ...</td>\n",
       "      <td>github</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>show hn  neural turing machine in pure numpy. ...</td>\n",
       "      <td>github</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>close look at a flu outbreak upends some commo...</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lambdalite  a functional  relational lisp data...</td>\n",
       "      <td>github</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   source\n",
       "0            holy cash cow  batman - content is back  nytimes\n",
       "1  show hn  a simple and configurable deployment ...   github\n",
       "2  show hn  neural turing machine in pure numpy. ...   github\n",
       "3  close look at a flu outbreak upends some commo...  nytimes\n",
       "4  lambdalite  a functional  relational lisp data...   github"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_NAME = \"titles_full.csv\"\n",
    "TITLE_SAMPLE_PATH = os.path.join(DATA_DIR, DATASET_NAME)\n",
    "COLUMNS = ['title', 'source']\n",
    "\n",
    "titles_df = pd.read_csv(TITLE_SAMPLE_PATH, header=None, names=COLUMNS)\n",
    "titles_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll find how many words we have in our dataset (`VOCAB_SIZE`), how many titles we have (`DATASET_SIZE`), and what the maximum length of the titles we have (`MAX_LEN`) is. Keras offers the `Tokenizer` class in its `keras.preprocessing.text` module to help us with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(titles_df.title)\n",
    "integerized_titles = tokenizer.texts_to_sequences(titles_df.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable 'integerized_titles' contains the integer representation of each article title in out dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6117, 560, 8577, 13948, 302, 13, 172],\n",
       " [11, 12, 2, 49, 7, 3838, 1322, 91, 4, 28, 482],\n",
       " [11, 12, 1501, 2812, 322, 5, 589, 7337, 5458, 78, 108, 1989, 17, 1139]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integerized_titles[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this and the `tokenizer` we can extract the `VOCAB_SIZE`, `DATASET_SIZE` and `MAX_LEN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47271"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(tokenizer.index_word)\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96203"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_SIZE = tokenizer.document_count\n",
    "DATASET_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = max(len(sequence) for sequence in integerized_titles)\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data\n",
    "We'll need to pad the elements of our title to feed into the model. Keras has the helper functions `pad_sequence` for that on the top of the tokenizer methods.\n",
    "\n",
    "The function `create_sequences` will \n",
    "* take as input our titles as well as the maximum sentence length and \n",
    "* returns a list of the integers corresponding to our tokens padded to the sentence maximum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(texts, max_len=MAX_LEN):\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    padded_sequences = pad_sequences(sequences,\n",
    "                                     max_len,\n",
    "                                     padding='post')\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6117,   560,  8577, 13948,   302,    13,   172,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0],\n",
       "       [ 1030,   316,    23,     2,  3718,  7338, 13949,   214,   715,\n",
       "         4581,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_titles = create_sequences([\"holy cash cow  batman - content is back\",\n",
    "                                 \"close look at a flu outbreak upends some common wisdom\"])\n",
    "sample_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll convert our label to numeric, categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = {\n",
    "    'github': 0,\n",
    "    'nytimes': 1,\n",
    "    'techcrunch': 2\n",
    "}\n",
    "N_CLASSES = len(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(sources):\n",
    "    classes = [CLASSES[source] for source in sources]\n",
    "    one_hots = utils.to_categorical(classes)\n",
    "    return one_hots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN = int(DATASET_SIZE * 0.80)\n",
    "\n",
    "titles_df = pd.read_csv(TITLE_SAMPLE_PATH, header=None, names=COLUMNS)\n",
    "titles_train, sources_train = (\n",
    "    titles_df.title[:N_TRAIN], titles_df.source[:N_TRAIN])\n",
    "\n",
    "titles_valid, sources_valid = (\n",
    "    titles_df.title[N_TRAIN:], titles_df.source[N_TRAIN:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "github        29175\n",
       "techcrunch    24784\n",
       "nytimes       23003\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, prepare the data for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = create_sequences(titles_train), encode_labels(sources_train)\n",
    "X_valid, Y_valid = create_sequences(titles_valid), encode_labels(sources_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 6117,   560,  8577, 13948,   302,    13,   172,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   11,    12,     2,    49,     7,  3838,  1322,    91,     4,\n",
       "            28,   482,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   11,    12,  1501,  2812,   322,     5,   589,  7337,  5458,\n",
       "            78,   108,  1989,    17,  1139,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]],\n",
       "       dtype=int32),\n",
       " array([[0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:3], Y_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a DNN model\n",
    "\n",
    "The `build_dnn_model` function below returns a compiled Keras model that implements a simple embedding layer transforming the word integers into dense vectors, followed by a Dense softmax layer that returns the probabilities for each class.\n",
    "\n",
    "\n",
    "Note that we need to put a custom Keras Lambda layer in between the Embedding layer and the Dense softmax layer to do an average of the word vectors returned by the embedding layer. This is the average that's fed to the dense softmax layer. By doing so, we create a model that is simple but that loses information about the word order, creating a model that sees sentences as \"bag-of-words\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dnn_model(embed_dim):\n",
    "\n",
    "    model = models.Sequential([\n",
    "        layers.Embedding(VOCAB_SIZE + 1,\n",
    "                         embed_dim,\n",
    "                         input_shape=[MAX_LEN]),\n",
    "        layers.Lambda(lambda x: tf.reduce_mean(x, axis=1)),\n",
    "        layers.Dense(N_CLASSES, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76962, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/257 [..............................] - ETA: 0s - loss: 1.0968 - accuracy: 0.3333WARNING:tensorflow:From /srv/hops/anaconda/envs/theenv/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 1.0480 - accuracy: 0.4314 - val_loss: 0.9781 - val_accuracy: 0.5766\n",
      "Epoch 2/100\n",
      "257/257 [==============================] - 1s 6ms/step - loss: 0.8878 - accuracy: 0.6790 - val_loss: 0.8058 - val_accuracy: 0.7134\n",
      "Epoch 3/100\n",
      "257/257 [==============================] - 1s 6ms/step - loss: 0.7347 - accuracy: 0.7798 - val_loss: 0.6831 - val_accuracy: 0.7852\n",
      "Epoch 4/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 0.6262 - accuracy: 0.8126 - val_loss: 0.5956 - val_accuracy: 0.8058\n",
      "Epoch 5/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 0.5461 - accuracy: 0.8303 - val_loss: 0.5329 - val_accuracy: 0.8202\n",
      "Epoch 6/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 0.4872 - accuracy: 0.8431 - val_loss: 0.4884 - val_accuracy: 0.8266\n",
      "Epoch 7/100\n",
      "257/257 [==============================] - 1s 6ms/step - loss: 0.4433 - accuracy: 0.8526 - val_loss: 0.4562 - val_accuracy: 0.8359\n",
      "Epoch 8/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 0.4095 - accuracy: 0.8607 - val_loss: 0.4328 - val_accuracy: 0.8405\n",
      "Epoch 9/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 0.3827 - accuracy: 0.8677 - val_loss: 0.4140 - val_accuracy: 0.8428\n",
      "Epoch 10/100\n",
      "257/257 [==============================] - 1s 6ms/step - loss: 0.3606 - accuracy: 0.8735 - val_loss: 0.4000 - val_accuracy: 0.8471\n",
      "Epoch 11/100\n",
      "257/257 [==============================] - 1s 6ms/step - loss: 0.3421 - accuracy: 0.8786 - val_loss: 0.3889 - val_accuracy: 0.8484\n",
      "Epoch 12/100\n",
      "257/257 [==============================] - 1s 6ms/step - loss: 0.3259 - accuracy: 0.8838 - val_loss: 0.3804 - val_accuracy: 0.8512\n",
      "Epoch 13/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 0.3118 - accuracy: 0.8886 - val_loss: 0.3726 - val_accuracy: 0.8527\n",
      "Epoch 14/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 0.2991 - accuracy: 0.8930 - val_loss: 0.3671 - val_accuracy: 0.8542\n",
      "Epoch 15/100\n",
      "257/257 [==============================] - 1s 6ms/step - loss: 0.2876 - accuracy: 0.8971 - val_loss: 0.3623 - val_accuracy: 0.8556\n",
      "Epoch 16/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 0.2773 - accuracy: 0.9004 - val_loss: 0.3589 - val_accuracy: 0.8565\n",
      "Epoch 17/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 0.2675 - accuracy: 0.9041 - val_loss: 0.3560 - val_accuracy: 0.8574\n",
      "Epoch 18/100\n",
      "257/257 [==============================] - 1s 6ms/step - loss: 0.2585 - accuracy: 0.9073 - val_loss: 0.3538 - val_accuracy: 0.8586\n",
      "Epoch 19/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 0.2502 - accuracy: 0.9100 - val_loss: 0.3525 - val_accuracy: 0.8595\n",
      "Epoch 20/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 0.2422 - accuracy: 0.9132 - val_loss: 0.3514 - val_accuracy: 0.8600\n",
      "Epoch 21/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 0.2348 - accuracy: 0.9158 - val_loss: 0.3512 - val_accuracy: 0.8605\n",
      "Epoch 22/100\n",
      "257/257 [==============================] - 1s 6ms/step - loss: 0.2278 - accuracy: 0.9180 - val_loss: 0.3512 - val_accuracy: 0.8609\n",
      "Epoch 23/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 0.2211 - accuracy: 0.9205 - val_loss: 0.3513 - val_accuracy: 0.8611\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 26, 10)            472720    \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 472,753\n",
      "Trainable params: 472,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "CPU times: user 1min 10s, sys: 30.3 s, total: 1min 40s\n",
      "Wall time: 35.4 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tf.random.set_seed(33)\n",
    "\n",
    "MODEL_DIR = os.path.join(LOGDIR, 'dnn')\n",
    "shutil.rmtree(MODEL_DIR, ignore_errors=True)\n",
    "\n",
    "BATCH_SIZE = 300\n",
    "EPOCHS = 100\n",
    "EMBED_DIM = 10\n",
    "PATIENCE = 0\n",
    "\n",
    "dnn_model = build_dnn_model(embed_dim=EMBED_DIM)\n",
    "\n",
    "dnn_history = dnn_model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_valid, Y_valid),\n",
    "    callbacks=[callbacks.EarlyStopping(patience=PATIENCE),\n",
    "               callbacks.TensorBoard(MODEL_DIR)],\n",
    ")\n",
    "\n",
    "pd.DataFrame(dnn_history.history)[['loss', 'val_loss']].plot()\n",
    "pd.DataFrame(dnn_history.history)[['accuracy', 'val_accuracy']].plot()\n",
    "\n",
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning with Pre-trained Embedding\n",
    "\n",
    "We can also use a word embedding from a pre-trained modle using a [Neural Probabilistic Language Model](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf). TF-Hub has a 50-dimensional one called \n",
    "[nnlm-en-dim50-with-normalization](https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1), which also normalizes the vectors produced. \n",
    "\n",
    "Once loaded from its url, the TF-hub module can be used as a normal Keras layer in a sequential or functional model. Since we have enough data to fine-tune the parameters of the pre-trained embedding itself, we will set `trainable=True` in the `KerasLayer` that loads the pre-trained embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNLM = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
    "\n",
    "nnlm_module = KerasLayer(\n",
    "    handle=NNLM,\n",
    "    output_shape=[50],\n",
    "    input_shape=[],\n",
    "    dtype=tf.string,\n",
    "    trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this module, we do not need to pad our inputs. The NNLM module returns a 50-dimensional vector given a word or sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=float32, numpy=\n",
       "array([[ 0.0958989 , -0.342834  , -0.0492865 , -0.09070477,  0.15877676,\n",
       "        -0.2123544 ,  0.28213888, -0.02812294, -0.07855891, -0.13102815,\n",
       "         0.11162009,  0.00899507,  0.01711924,  0.3225362 , -0.13289747,\n",
       "         0.11935385,  0.04386024,  0.06534779,  0.22004679, -0.13539287,\n",
       "        -0.0296053 , -0.06080014,  0.12862371,  0.23304915, -0.04424817,\n",
       "         0.07436226, -0.1898077 , -0.13270935,  0.21959057,  0.10597933,\n",
       "         0.03580458,  0.14275001, -0.0662442 , -0.3247055 ,  0.0461876 ,\n",
       "        -0.11603005,  0.06651007,  0.10887001, -0.05413236, -0.07126983,\n",
       "         0.02225055,  0.26454857, -0.04697315,  0.06729111, -0.14438024,\n",
       "         0.06355231, -0.05749882, -0.04587578,  0.23790349,  0.25837898],\n",
       "       [ 0.11347695, -0.04064287,  0.1053718 , -0.2368139 , -0.08755025,\n",
       "        -0.29770336, -0.00098698,  0.2312349 , -0.05596383,  0.04687293,\n",
       "         0.07230621, -0.10018747,  0.17597003, -0.04471372, -0.16409421,\n",
       "        -0.21718104, -0.13013352,  0.10073684,  0.04346658, -0.121227  ,\n",
       "        -0.05811132, -0.17935495,  0.08445173, -0.18978111,  0.14924097,\n",
       "         0.1283434 , -0.14006372,  0.10938524,  0.00990795, -0.31790745,\n",
       "        -0.04520534, -0.02819821,  0.13765122, -0.06532548, -0.18180048,\n",
       "         0.03769377, -0.12396756, -0.10564797,  0.01820223, -0.22254522,\n",
       "         0.06358314, -0.25590476,  0.25336912,  0.2768555 , -0.09150941,\n",
       "        -0.1493839 , -0.08984404,  0.13982305,  0.4764217 , -0.17479022]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnlm_module(tf.constant([\"holy cash cow  batman - content is back\",\n",
    "                         \"close look at a flu outbreak upends some common wisdom\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this in mind, we can simplify our data inputs since do not need to integerize or pad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = titles_train.values, encode_labels(sources_train)\n",
    "X_valid, Y_valid = titles_valid.values, encode_labels(sources_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['holy cash cow  batman - content is back',\n",
       "       'show hn  a simple and configurable deployment tool for github projects',\n",
       "       'show hn  neural turing machine in pure numpy. implements all 5 tasks from paper'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build DNN model using TF-Hub Embedding layer\n",
    "\n",
    "Next, we can add this TF-Hub module to our DNN model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hub_model():\n",
    "    model = models.Sequential([\n",
    "        KerasLayer(handle=NNLM,\n",
    "                   output_shape=[50],\n",
    "                   input_shape=[],\n",
    "                   dtype=tf.string,\n",
    "                   trainable=True),\n",
    "        layers.Dense(N_CLASSES, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7fc5c77fc830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7fc5c77fc830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 72/257 [=======>......................] - ETA: 1:08 - loss: 0.9545 - accuracy: 0.5976"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tf.random.set_seed(33)\n",
    "\n",
    "MODEL_DIR = os.path.join(LOGDIR, 'hub')\n",
    "shutil.rmtree(MODEL_DIR, ignore_errors=True)\n",
    "\n",
    "BATCH_SIZE = 300\n",
    "EPOCHS = 100\n",
    "EMBED_DIM = 10\n",
    "PATIENCE = 3\n",
    "\n",
    "hub_model = build_hub_model()\n",
    "\n",
    "hub_history = hub_model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_valid, Y_valid),\n",
    "    callbacks=[callbacks.EarlyStopping(patience=PATIENCE),\n",
    "               callbacks.TensorBoard(MODEL_DIR)],\n",
    ")\n",
    "\n",
    "pd.DataFrame(hub_history.history)[['loss', 'val_loss']].plot()\n",
    "pd.DataFrame(hub_history.history)[['accuracy', 'val_accuracy']].plot()\n",
    "\n",
    "hub_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
